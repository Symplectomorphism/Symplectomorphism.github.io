---
title: "Week 2: Introduction to Learning"
format: html
filters:
  - shinylive
---


::: {.panel-tabset}

## Overview 

::: {.column-margin}
Image credits: [Understanding Deep Learning](https://udlbook.github.io/udlbook) by Simon J. D. Prince, [CC BY 4.0]
:::

<!-- ![[Understanding Deep Learning](https://udlbook.github.io/udlbook), by Simon J. D. Prince, [CC BY 4.0]](assets/images/IntroOverview.svg){.lightbox} -->

<!--
::: {layout="[85, 15]" layout-valign="center"}
![Categories of Learning](assets/images/IntroOverview.svg){.lightbox}

Image credit: [Understanding Deep Learning](https://udlbook.github.io/udlbook) by Simon J. D. Prince, [CC BY 4.0]
:::
-->
![Categories of Learning](assets/images/IntroOverview.svg){.lightbox}

### Supervised Learning

* Define a mapping from input to output
* Learn this mapping from paired input/output data examples

#### Regression
![](assets/images/regression.svg){.lightbox}

#### Graph Regression
![](assets/images/graph_regression.svg){.lightbox}

#### Text Classification
![](assets/images/text_classification.svg){.lightbox}

#### Music Genre Classification
![](assets/images/music_genre_classification.svg){.lightbox}

#### Image Classification
![](assets/images/image_classification.svg){.lightbox}

### What is a supervised learning model?
![](assets/images/IntroAgeHeight.svg){.lightbox}

* An equation relating input (age) to output (height)
* Search through a family of possible equations to find one that fits training data well
* Deep neural networks are just a very flexible family of equations
* Fitting deep neural networks = "Deep Learning"


#### Image Segmentation
![](assets/images/image_segmentation.svg){.lightbox}

* Multivariate binary classification problem (many outputs, two discrete classes)
* Convolutional encoder-decoder network

#### Depth Estimation
![](assets/images/depth_estimation.svg){.lightbox}

* Multivariate regression problem (many output, continuous)
* Convolutional encoder-decoder network

#### Pose Estimation
![](assets/images/pose_estimation.png){.lightbox}

* Multivariate regression problem (many output, continuous)
* Convolutional encoder-decoder network

:::{.callout-tip}
#### Terms
* Regression: continuous numbers as output
* Classification: discrete classes as output
* Two class and multiclass classification are treated somewhat differently.
* Univariate: one output
* Multivariate: more than one output
:::

#### Translation
![](assets/images/translation.svg){.lightbox}

#### Image Captioning
![](assets/images/image_captioning.png){.lightbox}

#### Image Generation from Text
![](assets/images/generation_from_text.svg){.lightbox}

All these examples have in common:

* Very complex relationship between input and ouput
* Sometimes there may be many possible valid answers
* However, outputs (and sometimes inputs) obey certain rules (e.g. grammar)

The idea might be

* Learn the "grammar" of the data from unlabeled examples
* Here we can use a gargantuan amount of data (unlabeled)
* This makes the supervised learning task easier by having a lot of knowledge of possible outputs


### Unsupervised Learning


::: {layout="[85, 15]" layout-valign="center"}
* Learning about a dataset without labels: e.g. clustering
* Generative models can create examples: e.g. diffusion models
* PGMs learn distribution over data: e.g. VAEs, normalizing flows

![](assets/images/unsupervised_learning.png){.lightbox}
:::

#### Latent Variables
![](assets/images/latent.png){.lightbox}


### Reinforcement Learning
![](assets/images/IntroReinforce.svg){.lightbox}

* [States]{style="color: orange;"} are valid positions of the chess board
* [Actions]{style="color: orange;"} at a given position are valid possible moves
* Positive [rewards]{style="color: orange;"} for taking pieces, negative [rewards]{style="color: orange;"} for losing them

* Goal: take actions to change the state so that you receive rewards
* You don't receive any data - you have to explore the environment yourself to gather data as you go.

#### Why is this difficult?

* Stochastic
  - Make the same move twice, the opponent might not do the same thing
  - Rewards also stochastic (opponent does or does not take your piece)
* Temporal credit assignment problem
  - Did we get the reward b/c of this move or b/c/ we made good tactical decisions somewhere in the past?
* Exploration-exploitation trade-off
  - If we found a good opening, should we stick to it?
  - Should we try other things, hoping for something better?


## Supervised Learning

* [Supervised learning model]{style="color: orange;"} defined a mapping from one or more inputs to one or more outputs
* The model is a [family of]{style="color: orange;"} mathematical equations
* Computing the outputs given the inputs is termed [inference]{style="color: orange;"}

:::{.callout-note}
### Example
* Input: age and milage of a second-hand Toyota Prius
* Output: estimated price of car
:::

* Model also includes [parameters]{style="color: orange;"}
* Parameters affect the outcome of the model (equation)
* [Training]{style="color: orange;"} a model: finding parameters that predict the outputs "well"
  - Given inputs for a [training dataset]{style="color: orange;"} of input/output pairs

### Notation

* Input: $\bm{x} \in \R^n$
* Output: $\bm{y} \in \R^m$
* Model: $\bm{y} = \bm{f}(\bm{x}; \bm{\phi})$
* Parameters: $\bm{\phi} \in \R^p$

### Loss function

* Training dataset: $I$ pairs of input/output examples: $\left\{ \bm{x}_i, \bm{y}_i \right\}_{i=1}^I$
* [Loss function]{style="color: orange;"} or [cost function]{style="color: orange;"} measures how bad the model is:
$$
\bm{L}\left(\bm{\phi}, \underbrace{\bm{f}(\bm{x}; \bm{\phi})}_{\text{model}}, \left\{ \bm{x}_i, \bm{y}_i \right\}_{i=1}^I\right)
$$

or for short $\bm{L}(\bm{\phi})$

### Training
* Find the parameters that minimize the loss:
$$
\hat{\bm{\phi}} = \argmin_{\bm{\phi}}\; \mc{L}(\bm{\phi})
$$

### Testing

* To test the model, run on a separate [test dataset]{style="color: orange;"} of input/output pairs
* See how well it [generalizes]{style="color: orange;"} to new data

:::